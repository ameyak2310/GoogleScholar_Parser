{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c30bf153",
   "metadata": {},
   "source": [
    "# Google Scholar Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf48c2",
   "metadata": {},
   "source": [
    "### Getting Environment list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c52606f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                  *  C:\\Users\\ameya\\anaconda3\n",
      "Analysis                 C:\\Users\\ameya\\anaconda3\\envs\\Analysis\n",
      "ChamTest                 C:\\Users\\ameya\\anaconda3\\envs\\ChamTest\n",
      "Resource_Notes           C:\\Users\\ameya\\anaconda3\\envs\\Resource_Notes\n",
      "ReviewFlask              C:\\Users\\ameya\\anaconda3\\envs\\ReviewFlask\n",
      "ReviewFlask01            C:\\Users\\ameya\\anaconda3\\envs\\ReviewFlask01\n",
      "firstAPI                 C:\\Users\\ameya\\anaconda3\\envs\\firstAPI\n",
      "pyCFD                    C:\\Users\\ameya\\anaconda3\\envs\\pyCFD\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda env list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f22dd",
   "metadata": {},
   "source": [
    "### Activating enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cbf73b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda activate ReviewFlask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612b114",
   "metadata": {},
   "source": [
    "### Installing requirments and denpendancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7185fcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4==4.9.1Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "anaconda-project 0.10.2 requires ruamel-yaml, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached beautifulsoup4-4.9.1-py3-none-any.whl (115 kB)\n",
      "Collecting bs4==0.0.1\n",
      "  Using cached bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting certifi==2020.6.20\n",
      "  Using cached certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n",
      "Collecting chardet==3.0.4\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting click==7.1.2\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied: Flask==1.1.2 in c:\\users\\ameya\\anaconda3\\lib\\site-packages (from -r C:\\Users\\ameya\\Dropbox\\CourseWork\\FSDS\\TestSite\\ReviewFlask\\requirements.txt (line 6)) (1.1.2)\n",
      "Collecting Flask-Cors==3.0.9\n",
      "  Using cached Flask_Cors-3.0.9-py2.py3-none-any.whl (14 kB)\n",
      "Collecting gunicorn==20.0.4\n",
      "  Using cached gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)\n",
      "Collecting idna==2.10\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting itsdangerous==1.1.0\n",
      "  Using cached itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Jinja2==2.11.2\n",
      "  Using cached Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in c:\\users\\ameya\\anaconda3\\lib\\site-packages (from -r C:\\Users\\ameya\\Dropbox\\CourseWork\\FSDS\\TestSite\\ReviewFlask\\requirements.txt (line 12)) (1.1.1)\n",
      "Collecting requests==2.24.0\n",
      "  Using cached requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting six==1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting soupsieve==2.0.1\n",
      "  Using cached soupsieve-2.0.1-py3-none-any.whl (32 kB)\n",
      "Collecting urllib3==1.25.10\n",
      "  Using cached urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\n",
      "Collecting Werkzeug==1.0.1\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Requirement already satisfied: pymongo in c:\\users\\ameya\\anaconda3\\lib\\site-packages (from -r C:\\Users\\ameya\\Dropbox\\CourseWork\\FSDS\\TestSite\\ReviewFlask\\requirements.txt (line 18)) (4.0.1)\n",
      "Requirement already satisfied: setuptools>=3.0 in c:\\users\\ameya\\anaconda3\\lib\\site-packages (from gunicorn==20.0.4->-r C:\\Users\\ameya\\Dropbox\\CourseWork\\FSDS\\TestSite\\ReviewFlask\\requirements.txt (line 8)) (58.0.4)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1271 sha256=0647df00ebfacabd46b71079422ae39be555ce24be83a007d9f4aebb8b4b1179\n",
      "  Stored in directory: c:\\users\\ameya\\appdata\\local\\pip\\cache\\wheels\\75\\78\\21\\68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "Successfully built bs4\n",
      "Installing collected packages: Werkzeug, soupsieve, Jinja2, itsdangerous, click, urllib3, six, idna, chardet, certifi, beautifulsoup4, requests, gunicorn, Flask-Cors, bs4\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 2.0.2\n",
      "    Uninstalling Werkzeug-2.0.2:\n",
      "      Successfully uninstalled Werkzeug-2.0.2\n",
      "  Attempting uninstall: soupsieve\n",
      "    Found existing installation: soupsieve 2.3.1\n",
      "    Uninstalling soupsieve-2.3.1:\n",
      "      Successfully uninstalled soupsieve-2.3.1\n",
      "  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 2.11.3\n",
      "    Uninstalling Jinja2-2.11.3:\n",
      "      Successfully uninstalled Jinja2-2.11.3\n",
      "  Attempting uninstall: itsdangerous\n",
      "    Found existing installation: itsdangerous 2.0.1\n",
      "    Uninstalling itsdangerous-2.0.1:\n",
      "      Successfully uninstalled itsdangerous-2.0.1\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.3\n",
      "    Uninstalling click-8.0.3:\n",
      "      Successfully uninstalled click-8.0.3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.7\n",
      "    Uninstalling urllib3-1.26.7:\n",
      "      Successfully uninstalled urllib3-1.26.7\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.3\n",
      "    Uninstalling idna-3.3:\n",
      "      Successfully uninstalled idna-3.3\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2021.10.8\n",
      "    Uninstalling certifi-2021.10.8:\n",
      "      Successfully uninstalled certifi-2021.10.8\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.10.0\n",
      "    Uninstalling beautifulsoup4-4.10.0:\n",
      "      Successfully uninstalled beautifulsoup4-4.10.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.26.0\n",
      "    Uninstalling requests-2.26.0:\n",
      "      Successfully uninstalled requests-2.26.0\n",
      "Successfully installed Flask-Cors-3.0.9 Jinja2-2.11.2 Werkzeug-1.0.1 beautifulsoup4-4.9.1 bs4-0.0.1 certifi-2020.6.20 chardet-3.0.4 click-7.1.2 gunicorn-20.0.4 idna-2.10 itsdangerous-1.1.0 requests-2.24.0 six-1.15.0 soupsieve-2.0.1 urllib3-1.25.10\n"
     ]
    }
   ],
   "source": [
    "pip install -r C:\\Users\\ameya\\Dropbox\\CourseWork\\FSDS\\TestSite\\ReviewFlask\\requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9302de77",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a4a723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request,jsonify\n",
    "from flask_cors import CORS,cross_origin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "#from urllib.request import urlopen, Request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2a6cc",
   "metadata": {},
   "source": [
    "## Making Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ead0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be8d446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_STRING = r\"RNN\" \n",
    "SITE   = r'https://scholar.google.com/scholar'\n",
    "headers = {'User-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'    }\n",
    "params  = {'q' : SEARCH_STRING,    # search query\n",
    "           'hl': 'en'       # language of the search\n",
    "          }\n",
    "\n",
    "PAGE_HTML = requests.get(SITE, headers=headers, params=params).text\n",
    "PAGE_SOUP = BeautifulSoup(PAGE_HTML, 'lxml')\n",
    "ARTICLES  = PAGE_SOUP.select('.gs_r.gs_or.gs_scl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0c95bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLES_DATA = []\n",
    "for ARTICLE in ARTICLES:\n",
    "        TITLE            = ARTICLE.select_one('.gs_rt').text\n",
    "        PUBLICATION_INFO = ARTICLE.select_one('.gs_a').text\n",
    "        AUTHOR           = PUBLICATION_INFO.split('-')[0].split('\\xa0')[0]\n",
    "        JOURNAL          = PUBLICATION_INFO.split('-')[1].split('\\xa0')[0]\n",
    "        PUBLICATION_YEAR = PUBLICATION_INFO.split('-')[1].split()[-1]\n",
    "        HOST             = PUBLICATION_INFO.split('-')[-1]\n",
    "        HOST_URL         = ARTICLE.select_one('.gs_rt a')['href']\n",
    "        ABSTRACT         = ARTICLE.select_one('.gs_rs').text\n",
    "        \n",
    "        CITE_INFO        = ARTICLE.select_one('a:contains(\"Cited by\")').text if ARTICLE.select_one('a:contains(\"Cited by\")') is not None else 'No citation count'\n",
    "        CITATIONS        = CITE_INFO.split(sep=\" \")[-1]\n",
    "        \n",
    "        try:\n",
    "            PDF_LINK     = ARTICLE.select_one('.gs_or_ggsm a:nth-child(1)')['href']\n",
    "        except: \n",
    "            PDF_LINK     = None\n",
    "        \n",
    "        ARTICLE_DATA     = {'TITLE'           : TITLE,\n",
    "                            'AUTHOR'          : AUTHOR,\n",
    "                            'PUBLICATION_YEAR': PUBLICATION_YEAR,\n",
    "                            'JOURNAL'         : JOURNAL,\n",
    "                            'HOST'            : HOST,\n",
    "                            'HOST_URL'        : HOST_URL,\n",
    "                            'ABSTRACT'        : ABSTRACT,\n",
    "                            'CITATIONS'       : CITATIONS,\n",
    "                            \"PDF_LINK\"        : PDF_LINK,\n",
    "                            }\n",
    "        ARTICLES_DATA.append(ARTICLE_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f1ced3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'TITLE': 'A clockwork rnn',\n",
       "  'AUTHOR': 'J Koutnik, K Greff, F Gomez…',\n",
       "  'PUBLICATION_YEAR': '2014',\n",
       "  'JOURNAL': ' …',\n",
       "  'HOST': ' proceedings.mlr.press',\n",
       "  'HOST_URL': 'http://proceedings.mlr.press/v32/koutnik14.html',\n",
       "  'ABSTRACT': '… modification to the simple RNN (SRN) architecture, the Clockwork RNN (CW-RNN), in which \\nthe … Rather than making the standard RNN models more complex, CW-RNN reduces the …',\n",
       "  'CITATIONS': '551',\n",
       "  'PDF_LINK': 'http://proceedings.mlr.press/v32/koutnik14.pdf'},\n",
       " {'TITLE': 'Comparative study of CNN and RNN for natural language processing',\n",
       "  'AUTHOR': 'W Yin, K Kann, M Yu, H Schütze',\n",
       "  'PUBLICATION_YEAR': '2017',\n",
       "  'JOURNAL': ' arXiv preprint arXiv:1702.01923, 2017 ',\n",
       "  'HOST': ' arxiv.org',\n",
       "  'HOST_URL': 'https://arxiv.org/abs/1702.01923',\n",
       "  'ABSTRACT': '… network (CNN) and recurrent neural network (RNN), the two … position-invariant features \\nand RNN at modeling units in … This work is the first systematic comparison of CNN and RNN …',\n",
       "  'CITATIONS': '941',\n",
       "  'PDF_LINK': 'https://arxiv.org/pdf/1702.01923'},\n",
       " {'TITLE': 'Fundamentals of recurrent neural network (RNN) and long short-term memory (LSTM) network',\n",
       "  'AUTHOR': 'A Sherstinsky',\n",
       "  'PUBLICATION_YEAR': '2020',\n",
       "  'JOURNAL': ' Physica D: Nonlinear Phenomena, 2020 ',\n",
       "  'HOST': ' Elsevier',\n",
       "  'HOST_URL': 'https://www.sciencedirect.com/science/article/pii/S0167278919305974',\n",
       "  'ABSTRACT': '… with training the standard RNN and address them by transforming the RNN into the “Vanilla … \\non the RNN first, because the LSTM network is a type of an RNN, and since the RNN is a …',\n",
       "  'CITATIONS': '1692',\n",
       "  'PDF_LINK': 'https://arxiv.org/pdf/1808.03314'},\n",
       " {'TITLE': 'A comparative study of RNN for outlier detection in data mining',\n",
       "  'AUTHOR': 'G Williams, R Baxter, H He…',\n",
       "  'PUBLICATION_YEAR': '2002',\n",
       "  'JOURNAL': ' 2002 IEEE International',\n",
       "  'HOST': ' ieeexplore.ieee.org',\n",
       "  'HOST_URL': 'https://ieeexplore.ieee.org/abstract/document/1184035/',\n",
       "  'ABSTRACT': 'We have proposed replicator neural networks (RNNs) for outlier detection. We compare \\nRNN for outlier detection with three other methods using both publicly available statistical …',\n",
       "  'CITATIONS': '379',\n",
       "  'PDF_LINK': 'https://togaware.com/papers/icdm02.pdf'},\n",
       " {'TITLE': 'Independently recurrent neural network (indrnn): Building a longer and deeper rnn',\n",
       "  'AUTHOR': 'S Li, W Li, C Cook, C Zhu…',\n",
       "  'PUBLICATION_YEAR': '2018',\n",
       "  'JOURNAL': ' Proceedings of the IEEE',\n",
       "  'HOST': ' openaccess.thecvf.com',\n",
       "  'HOST_URL': 'http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Independently_Recurrent_Neural_CVPR_2018_paper.html',\n",
       "  'ABSTRACT': '… RNN layer are entangled together and their behaviour is hard to interpret. To address these \\nproblems, a new type of RNN, referred to as independently recurrent neural network (In… RNN …',\n",
       "  'CITATIONS': '649',\n",
       "  'PDF_LINK': 'http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Independently_Recurrent_Neural_CVPR_2018_paper.pdf'},\n",
       " {'TITLE': 'Learning phrase representations using RNN encoder-decoder for statistical machine translation',\n",
       "  'AUTHOR': 'K Cho, B Van Merriënboer, C Gulcehre…',\n",
       "  'PUBLICATION_YEAR': '2014',\n",
       "  'JOURNAL': ' arXiv preprint arXiv',\n",
       "  'HOST': ' arxiv.org',\n",
       "  'HOST_URL': 'https://arxiv.org/abs/1406.1078',\n",
       "  'ABSTRACT': '… to as an RNN Encoder–Decoder, consists of two recurrent neural networks (RNN) that act as \\n… The proposed RNN Encoder–Decoder with a novel hidden unit is empirically evaluated on …',\n",
       "  'CITATIONS': '22003',\n",
       "  'PDF_LINK': 'https://arxiv.org/pdf/1406.1078.pdf?source=post_page---------------------------'},\n",
       " {'TITLE': 'Deep captioning with multimodal recurrent neural networks (m-rnn)',\n",
       "  'AUTHOR': 'J Mao, W Xu, Y Yang, J Wang, Z Huang…',\n",
       "  'PUBLICATION_YEAR': '2014',\n",
       "  'JOURNAL': ' arXiv preprint arXiv',\n",
       "  'HOST': ' arxiv.org',\n",
       "  'HOST_URL': 'https://arxiv.org/abs/1412.6632',\n",
       "  'ABSTRACT': '… -networks: a deep recurrent neural network for sentences and … to form the whole m-RNN \\nmodel. The effectiveness of our … In addition, we apply the m-RNN model to retrieval tasks for …',\n",
       "  'CITATIONS': '1332',\n",
       "  'PDF_LINK': 'https://arxiv.org/pdf/1412.6632.pdf%3E'},\n",
       " {'TITLE': 'A comparative study on transformer vs rnn in speech applications',\n",
       "  'AUTHOR': 'S Karita, N Chen, T Hayashi, T Hori…',\n",
       "  'PUBLICATION_YEAR': '2019',\n",
       "  'JOURNAL': ' 2019 IEEE Automatic',\n",
       "  'HOST': ' ieeexplore.ieee.org',\n",
       "  'HOST_URL': 'https://ieeexplore.ieee.org/abstract/document/9003750/',\n",
       "  'ABSTRACT': '… (RNN) in natural language processing tasks. This paper provides intensive comparisons of \\nits performance with that of RNN … ) than the conventional RNN based models. Our goal is to …',\n",
       "  'CITATIONS': '499',\n",
       "  'PDF_LINK': 'https://arxiv.org/pdf/1909.06317'},\n",
       " {'TITLE': 'Cnn-rnn: A unified framework for multi-label image classification',\n",
       "  'AUTHOR': 'J Wang, Y Yang, J Mao, Z Huang…',\n",
       "  'PUBLICATION_YEAR': '2016',\n",
       "  'JOURNAL': ' Proceedings of the',\n",
       "  'HOST': ' openaccess.thecvf.com',\n",
       "  'HOST_URL': 'http://openaccess.thecvf.com/content_cvpr_2016/html/Wang_CNN-RNN_A_Unified_CVPR_2016_paper.html',\n",
       "  'ABSTRACT': '… We find that RNN significantly improves classification accuracy. For the CNN part, to avoid \\nproblems like overfitting, previous methods normally assume all classifiers share the same …',\n",
       "  'CITATIONS': '1182',\n",
       "  'PDF_LINK': 'https://openaccess.thecvf.com/content_cvpr_2016/papers/Wang_CNN-RNN_A_Unified_CVPR_2016_paper.pdf'},\n",
       " {'TITLE': 'Structural-rnn: Deep learning on spatio-temporal graphs',\n",
       "  'AUTHOR': 'A Jain, AR Zamir, S Savarese…',\n",
       "  'PUBLICATION_YEAR': '2016',\n",
       "  'JOURNAL': ' Proceedings of the ieee',\n",
       "  'HOST': ' openaccess.thecvf.com',\n",
       "  'HOST_URL': 'http://openaccess.thecvf.com/content_cvpr_2016/html/Jain_Structural-RNN_Deep_Learning_CVPR_2016_paper.html',\n",
       "  'ABSTRACT': '… In S-RNN, we represent each factor with an RNN. We refer the RNNs obtained from the \\nnode factors as nodeRNNs and the RNNs obtained from the edge factors as edgeRNNs. The …',\n",
       "  'CITATIONS': '989',\n",
       "  'PDF_LINK': 'http://openaccess.thecvf.com/content_cvpr_2016/papers/Jain_Structural-RNN_Deep_Learning_CVPR_2016_paper.pdf'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARTICLES_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e4de527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import render_template\n",
    "render_template?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf3f9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
